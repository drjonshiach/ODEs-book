{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96461176",
   "metadata": {},
   "source": [
    "(basis-section)=\n",
    "# Basis\n",
    "\n",
    "## Spanning sets\n",
    "\n",
    "::::{admonition} Definition: Spanning set\n",
    ":class: note\n",
    ":name: spanning-set-definition\n",
    "\n",
    "Let $V$ be a vector space over the field $F$ and $S$ is a subset of $V$. Let $W$ be a subset of $V$ that are expressible as a linear combination of vectors in $S$, i.e., for $\\mathbf{u} \\in W$, $\\mathbf{v}_1, \\ldots, \\mathbf{v}_n \\in S$ and $\\alpha_1, \\ldots, \\alpha_n \\in F$\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{u} = \\alpha_1 \\mathbf{v}_1 + \\alpha_2 \\mathbf{v}_2 + \\cdots + \\alpha_n \\mathbf{v}_n.\n",
    "\\end{align*}\n",
    "then $W$ is a subspace of $V$ and $S$ is a **spanning set** for $W$. We write this as $\\operatorname{span}(S)$.\n",
    "::::\n",
    "\n",
    "For example, $\\mathbb{C} = \\operatorname{span}(\\{1, i\\})$ over $\\mathbb{R}$ since every element of $\\mathbb{C}$ can be expressed as a linear combination of 1 and $i$.\n",
    "\n",
    "::::{admonition} Example 5.6\n",
    ":class: seealso\n",
    ":name: spanning-set-example\n",
    "\n",
    "(i) &emsp; Show that  $\\{ \\mathbf{v}_1, \\mathbf{v}_2 \\}$ where $\\mathbf{v}_1 = (2, 1)$ and $\\mathbf{v}_2 = (4, 3)$ is a spanning set for $\\mathbb{R}^2$.\n",
    "\n",
    "\n",
    ":::{dropdown} Solution\n",
    "\n",
    "We need to show that $\\alpha_1 \\mathbf{v}_1 + \\alpha_2 \\mathbf{v}_2 = (a, b)$ for any $a, b \\in \\mathbb{R}$, i.e., so that the following system has a non-trivial solution.\n",
    "\n",
    "\\begin{align*}\n",
    "    2 \\alpha_1 + 4 \\alpha_2 &= a, \\\\\n",
    "    \\alpha_1 + 3 \\alpha_2 &= b. \n",
    "\\end{align*}\n",
    "\n",
    "A system of linear equations has a solution if it is [non-singular](inverse-matrix-definition) (the determinant of the coefficient matrix is non-zero), therefore\n",
    "\n",
    "\\begin{align*}\n",
    "    \\det \\begin{pmatrix} 2 & 4 \\\\ 1 & 3 \\end{pmatrix} = 2 \\neq 0, \n",
    "\\end{align*}\n",
    "\n",
    "so $\\{\\mathbf{v}_1, \\mathbf{v}_2\\}$ is a spanning set for $\\mathbb{R}^2$.\n",
    ":::\n",
    "\n",
    "(ii) &emsp; Determine a spanning set for $\\mathbb{R}^3$.\n",
    "\n",
    ":::{dropdown} Solution\n",
    "\n",
    "Lets suggest $\\{ (1, 0, 0), (0, 1, 0), (0, 0, 1) \\}$ as a spanning set for $\\mathbb{R}^3$\n",
    "\\begin{align*}\n",
    "    (x, y, z) &= \\{ \\alpha_1 (1, 0, 0) + \\alpha_2 (0, 1, 0) + \\alpha_3(0, 0, 1) : \\alpha_1, \\alpha_2, \\alpha_3 \\in \\mathbb{R}\\} \\\\\n",
    "    &= \\{ \\alpha_1 \\mathbf{i} + \\alpha_2 \\mathbf{j} + \\alpha_3 \\mathbf{k} : \\alpha_1, \\alpha_2, \\alpha_3 \\in \\mathbb{R} \\},\n",
    "\\end{align*}\n",
    "\n",
    "therefore $\\{ \\mathbf{i}, \\mathbf{j}, \\mathbf{k} \\}$ is a spanning set for $\\mathbb{R}^3$. Note that this is just one of many examples of spanning sets for $\\mathbb{R}^3$.\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "The vectors $\\mathbf{i}$, $\\mathbf{j}$ and $\\mathbf{j}$ were introduced in [basis vectors](basis-vectors-section). This leads to the definition of a basis of a vector space.\n",
    "\n",
    "## Basis of a vector space\n",
    "\n",
    "::::{admonition} Definition: Basis of a vector space\n",
    ":class: note\n",
    ":name: basis-definition\n",
    "    \n",
    "A **basis** of a vector space $V$ of a field $F$ is a linearly independent subset of $V$ that spans $V$. A subset $W$ is a basis if it satisfies the following\n",
    "\n",
    "- [linear independence property](linear-dependence-definition): for every subset $\\{\\mathbf{v}_1, \\ldots , \\mathbf{v}_n\\}$ of $W$ the following equation only has the trivial soluion $\\alpha_i = 0$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\alpha_1 \\mathbf{v}_1 + \\alpha_2 \\mathbf{v}_2 + \\cdots + \\alpha_n \\mathbf{v}_n &= \\mathbf{0};\n",
    "\\end{align*}\n",
    "\n",
    "- [spanning property](spanning-set-definition): for all $\\mathbf{u} \\in V$ we can write $\\mathbf{u}$ as a linear combination of $\\mathbf{v} \\in W$, i.e.,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{u} = \\alpha_1 \\mathbf{v}_1 + \\alpha_2 \\mathbf{v}_2 + \\cdots + \\alpha_n \\mathbf{v}_n.\n",
    "\\end{align*}\n",
    "::::\n",
    "\n",
    ":::{admonition} Definition: Orthogonal basis\n",
    ":class: note\n",
    ":name: orthogonal-basis-definition\n",
    "\n",
    "An **orthogonal basis** of a vector space is one in which each of the vectors are orthogonal (perpendicular) to one another.\n",
    ":::\n",
    "\n",
    ":::{admonition} Definition: Orthonormal basis\n",
    ":class: note\n",
    ":name: orthonormal-basis-definition\n",
    "\n",
    "An **orthonormal basis** of a vector space is one in which each of the vectors are orthogonal to one another and each vector is a unit vector.\n",
    ":::\n",
    "\n",
    ":::{admonition} Definition: Dimension of a vector space\n",
    ":class: note\n",
    ":name: vector-space-dimension-definition\n",
    "\n",
    "The **dimension** of a vector space $V$ is denoted by $\\dim(V)$ and is the number of elements in the basis for the vector space. \n",
    ":::\n",
    "\n",
    "::::{admonition} Example 5.7\n",
    ":class: seealso\n",
    ":name: basis-example\n",
    "\n",
    "Show that the vectors $\\mathbf{v}_1 = (1, 1, 0)$, $\\mathbf{v}_2 = (1, -1, 1)$ and $\\mathbf{v}_3 = (1, -1, -2)$ is a basis for $\\mathbb{R}^3$.\n",
    "\n",
    ":::{dropdown} Solution\n",
    "\n",
    "We need to show that the three vectors are linearly independent, i.e., show that the only solution to the following system is $\\alpha_1 = \\alpha_2 = \\alpha_3 = 0$\n",
    "\n",
    "\\begin{align*}\n",
    "    \\alpha_1 \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} +\n",
    "    \\alpha_2 \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} +\n",
    "    \\alpha_3 \\begin{pmatrix} 1 \\\\ -1 \\\\ -2 \\end{pmatrix}  = \n",
    "    \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Using Gauss-Jordan elimination\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\left( \\begin{array}{ccc|c}\n",
    "        1 & 1 & 1 & 0 \\\\\n",
    "        1 & -1 & 1 & 0\\\\\n",
    "        1 & -1 & -2 & 0\n",
    "    \\end{array} \\right)\n",
    "    \\begin{matrix} \\\\ R_2 - R_1 \\\\ R_3 - R_1 \\end{matrix} \\\\ \\\\\n",
    "    \\longrightarrow \\quad &\n",
    "    \\left( \\begin{array}{ccc|c}\n",
    "        1 & 1 & 1 & 0 \\\\\n",
    "        0 & -2 & 0 & 0\\\\\n",
    "        0 & -2 & -3 & 0\n",
    "    \\end{array} \\right)\n",
    "    \\begin{matrix} \\\\ -\\frac{1}{2}R_2 \\\\ \\phantom{x} \\end{matrix} \\\\ \\\\\n",
    "    \\longrightarrow \\quad &\n",
    "    \\left( \\begin{array}{ccc|c}\n",
    "        1 & 1 & 1 & 0 \\\\\n",
    "        0 & 1 & 0 & 0\\\\\n",
    "        0 & -2 & -3 & 0\n",
    "    \\end{array} \\right)\n",
    "    \\begin{matrix} R_1 - R_2 \\\\ \\\\ R_3 + 2R_2 \\end{matrix}  \\\\ \\\\\n",
    "    \\longrightarrow \\quad &\n",
    "    \\left( \\begin{array}{ccc|c}\n",
    "        1 & 0 & 1 & 0 \\\\\n",
    "        0 & 1 & 0 & 0\\\\\n",
    "        0 & 0 & -3 & 0\n",
    "    \\end{array} \\right)\n",
    "    \\begin{matrix} \\\\ \\phantom{x} \\\\ -\\frac{1}{3}R_3 \\end{matrix} \\\\ \\\\\n",
    "    \\longrightarrow \\quad &\n",
    "    \\left( \\begin{array}{ccc|c}\n",
    "        1 & 0 & 1 & 0 \\\\\n",
    "        0 & 1 & 0 & 0\\\\\n",
    "        0 & 0 & 1 & 0\n",
    "    \\end{array} \\right)\n",
    "    \\begin{matrix} R_1 - R_3 \\\\ \\phantom{x} \\\\ \\phantom{x} \\end{matrix} \\\\ \\\\\n",
    "    \\longrightarrow \\quad &\n",
    "    \\left( \\begin{array}{ccc|c}\n",
    "        1 & 0 & 0 & 0 \\\\\n",
    "        0 & 1 & 0 & 0\\\\\n",
    "        0 & 0 & 1 & 0\n",
    "    \\end{array} \\right)\n",
    "\\end{align*}\n",
    "So $\\mathbf{v}_1$, $\\mathbf{v}_2$ and $\\mathbf{v}_3$ are linearly independent. We also need to show that $\\{ \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\}$ spans $\\mathbb{R}^3$. \n",
    "\\begin{align*}\n",
    "    \\det \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & -1 & -1 \\\\ 0 & 1 & -2 \\end{pmatrix} = 3 + 3 = 6 \\neq 0,\n",
    "\\end{align*}\n",
    "so $\\{ \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\}$ is a spanning set for $\\mathbb{R}^3$. Note that in showing that $\\mathbf{v}_1$, $\\mathbf{v}_2$ and $\\mathbf{v}_3$ are linearly independent we have also shown that $\\alpha_1 \\mathbf{v}_1 + \\alpha_2 \\mathbf{v}_2 + \\alpha_3 \\mathbf{v}_3 = (a, b, c)$ has a solution and $\\{ \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\}$ is a spanning set. Futhermore \n",
    "\\begin{align*}\n",
    "    \\mathbf{v}_1 \\cdot \\mathbf{v}_2 &= \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\cdot\n",
    "    \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} = 0, \\\\\n",
    "    \\mathbf{v}_1 \\cdot \\mathbf{v}_3 &= \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\cdot\n",
    "    \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} = 0, \\\\\n",
    "    \\mathbf{v}_2 \\cdot \\mathbf{v}_3 &= \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} \\cdot\n",
    "    \\begin{pmatrix} 1 \\\\ -1 \\\\ -2 \\end{pmatrix} = 0,\n",
    "\\end{align*}\n",
    "so $\\{ \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3 \\}$ is an orthogonal basis. It is not an orthonormal basis since $|\\mathbf{v}_1| = \\sqrt{2} \\neq 1$.\n",
    ":::\n",
    "::::\n",
    "\n",
    "(change-of-basis-section)=\n",
    "## Change of basis\n",
    "\n",
    "$\\mathbb{R}^n$ has a particularly nice basis that is easy to write down\n",
    "\n",
    "\\begin{align*}\n",
    "    E = \\left\\{ \n",
    "        \\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}, \n",
    "        \\mathbf{e}_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}, \\ldots,\n",
    "        \\mathbf{e}_n = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{pmatrix} \n",
    "        \\right\\},\n",
    "\\end{align*}\n",
    "\n",
    "which is called the **standard basis**. Note that for $\\mathbb{R}^3$ we have $\\mathbf{i} = \\mathbf{e}_1$, $\\mathbf{j} = \\mathbf{e}_2$ and $\\mathbf{k} = \\mathbf{e}_3$ and $\\mathbf{e}_i$ is column $i$ of the identity matrix.\n",
    "\n",
    "We can represent a vector $\\mathbf{u} = (u_1, u_2, \\ldots, u_n) \\in \\mathbb{R}^n$ in the standard basis as a vector with respect to another basis $W = \\{\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n\\}$ which is denoted using $[\\mathbf{u}]_W$. Using the standard basis we have\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{u} &= u_1 \\mathbf{e}_1 + u_2 \\mathbf{e}_2 + \\cdots + u_n \\mathbf{e}_n = (u_1, u_2, \\ldots, u_n),\n",
    "\\end{align*}\n",
    "\n",
    "and to express $\\mathbf{u}$ with respect to the basis $W$ we need to solve \n",
    "\n",
    "\\begin{align*}\n",
    "    [\\mathbf{u}]_W &= w_1 \\mathbf{v}_1 + w_2 \\mathbf{v}_2 + \\cdots + w_n \\mathbf{v}_n = (w_1, w_2, \\ldots, w_n),\n",
    "\\end{align*}\n",
    "\n",
    "for $w_1, w_2, \\ldots, w_n$. This concept is illustrated for $\\mathbb{R}^2$ in {numref}`change-of-basis-figure`.\n",
    "\n",
    ":::{figure} ../Images/change_of_basis.png\n",
    ":name: change-of-basis-figure\n",
    "\n",
    "The vector $(u_1, u_2)$ in $\\mathbb{R}^2$ expressed with respect to the basis $E = \\{\\mathbf{e}_1, \\mathbf{e}_2 \\}$ and $W = \\{\\mathbf{v}_1, \\mathbf{v}_2\\}$.\n",
    ":::\n",
    "\n",
    "::::{admonition} Example 5.8\n",
    ":class: seealso\n",
    ":name: change-of-basis-example\n",
    "\n",
    "Represent the vector $\\mathbf{u} = (4, 0, 5)$ with respect to the basis $W = \\{(1, 1, 0), (1, -1, 1), (1, -1, -2)\\}$.\n",
    "\n",
    ":::{dropdown} Solution\n",
    "\n",
    "We need to solve the system\n",
    "\n",
    "\\begin{align*}\n",
    "    w_1 \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} + \n",
    "    w_2 \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} +\n",
    "    w_3 \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix} =\n",
    "    \\begin{pmatrix} 4 \\\\ 0 \\\\ 5 \\end{pmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "which can be written as the matrix equation\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix}\n",
    "        1 & 1 & 1 \\\\\n",
    "        1 & -1 & -1 \\\\\n",
    "        0 & 1 & 2 \n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{pmatrix} =\n",
    "    \\begin{pmatrix} 4 \\\\ 0 \\\\ 5 \\end{pmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "where $[\\mathbf{u}]_w = (w_1, w_2, w_3)$. Calculating the inverse of the coefficient matrix\n",
    "\n",
    "\\begin{align*}\n",
    "    \\begin{pmatrix} \n",
    "        1 & 1 & 1 \\\\\n",
    "        1 & -1 & -1 \\\\\n",
    "        0 & 1 & -2 \n",
    "    \\end{pmatrix}^{-1} &=\n",
    "    \\frac{1}{6}\n",
    "    \\begin{pmatrix}\n",
    "        3 & 2 & 1 \\\\\n",
    "        3 & -2 & -1 \\\\\n",
    "        0 & 2 & -2\n",
    "    \\end{pmatrix}^\\mathrm{T} \\\\\n",
    "    &= \\frac{1}{6} \n",
    "    \\begin{pmatrix}\n",
    "        3 & 3 & 0 \\\\\n",
    "        2 & -2 & 2 \\\\\n",
    "        1 & -1 & -2\n",
    "    \\end{pmatrix} \\\\\n",
    "    &=\n",
    "    \\begin{pmatrix} \n",
    "        \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n",
    "        \\frac{1}{3} & -\\frac{1}{3} & \\frac{1}{3} \\\\\n",
    "        \\frac{1}{6} & -\\frac{1}{6} & -\\frac{1}{3}\n",
    "    \\end{pmatrix},\n",
    "\\end{align*}\n",
    "\n",
    "so\n",
    "\n",
    "\\begin{align*}\n",
    "    [\\mathbf{u}]_W = \n",
    "    \\begin{pmatrix} \n",
    "        \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n",
    "        \\frac{1}{3} & -\\frac{1}{3} & \\frac{1}{3} \\\\\n",
    "        \\frac{1}{6} & -\\frac{1}{6} & -\\frac{1}{3}\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix} 4 \\\\ 0 \\\\ 5 \\end{pmatrix} =\n",
    "    \\begin{pmatrix} 2 \\\\ 3 \\\\ -1 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "::::\n",
    "\n",
    "Note that in [example 5.8](change-of-basis-example) we can represent any vector $\\mathbf{u}$ with respect to the basis $W$ by multiplying by the square matrix in the final equation. This matrix is known as the [**change of basis matrix**](https://en.wikipedia.org/wiki/Change_of_basis).\n",
    "\n",
    "::::{admonition} Definition: Change of basis matrix\n",
    ":class: note\n",
    ":name: change-of-basis-matrix-definition\n",
    "\n",
    "Let $V$ be a vector space over the field $F$ and $\\mathbf{u} \\in V$. If $E$ and $W$ are two basis for $V$ then the change of basis matrix is the matrix $A_{E \\to W}$ such that $[u]_{W} = A_{E \\to W} [u]_E$.\n",
    "::::\n",
    "\n",
    "So to express the vector $\\mathbf{u}$ to the basis $W$ we simply multiply $\\mathbf{u}$ by the change of basis matrix. Changing from a non-standard basis is a slightly more complicated procedure and will be covered in the more advanced materials on linear algebra."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
