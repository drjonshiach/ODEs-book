{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecbe797",
   "metadata": {},
   "source": [
    "(convergence-of-indirect-methods-section)=\n",
    "# Convergence of indirect methods\n",
    "\n",
    "We have seen that both the [Jacobi](jacobi-method-section) and [Gauss-Seidel](gauss-seidel-method-section) methods are iterated until the estimates of the solution converge to a given tolerance. In [example 7.1](jacobi-method-example) required 49 iterations to converge to the solution of a system of linear equations whereas in [example 7.2](gauss-seidel-method-example) only required 20 iterations to converge to the solution for the same system. \n",
    "\n",
    "Not all indirect methods will converge for a given system of linear equations, we can establish whether a method will be convergent using the theorem below. Let $\\mathbf{e}^{(k)} = |\\mathbf{x} - \\mathbf{x}^{(k)}|$ be the error between the exact solution $\\mathbf{x}$ and the estimate $\\mathbf{x}^{(k)}$. The error from one estimate to the next is updated using the iteration matrix for the method\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{e}^{(k+1)} = T\\mathbf{e}^{(k)}.\n",
    "\\end{align*}\n",
    "\n",
    "We can write the first error, $\\mathbf{e}^{(0)}$ as a linear combination of some vectors $\\mathbf{v}_i$ \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{e}^{(0)} =\\alpha_1 \\mathbf{v}_1 +\\alpha_2 \\mathbf{v}_2 +\\cdots +\\alpha_n \\mathbf{v}_n =\\sum_{i=1}^n \\alpha_i \\mathbf{v}_i,\n",
    "\\end{align*}\n",
    "\n",
    "where $\\alpha_i$ are scalars. If $\\mathbf{v}_i$ are the [eigenvectors](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) of the matrix $T$ with eigenvalues $\\lambda_i$ so $T\\mathbf{v}_i = \\lambda_i \\mathbf{v}_i$ then iterating $\\mathbf{e}^{(k)}$ gives\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{e}^{(1)} &= T\\mathbf{e}^{(0)} =T\\left(\\sum_{i=1}^n \\alpha_i \\mathbf{v}_i \\right)=\\sum_{i=1}^n \\alpha_i T\\mathbf{v}_i = \\sum_{i=1}^n \\alpha_i \\lambda_i \\mathbf{v}_i , \\\\\n",
    "    \\mathbf{e}^{(2)} &=T\\mathbf{e}^{(1)} =T\\left(\\sum_{i=1}^n \\alpha_i \\lambda_i \\mathbf{v}_i \\right)=\\sum_{i=1}^n \\alpha_i \\lambda_i T\\mathbf{v}_i =\\sum_{i=1}^n \\alpha_i \\lambda_i^2 \\mathbf{v}_i , \\\\\n",
    "    &\\vdots \\\\\n",
    "    \\mathbf{e}^{(k+1)} &=\\sum_{i=1}^n \\alpha_i \\lambda_i^{k+1} \\mathbf{v}_i .\n",
    "\\end{align*}\n",
    "\n",
    "If $|\\lambda_1|>\\lambda_2, \\lambda_3, \\ldots \\lambda_n$ then\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{e}^{(k+1)} =\\alpha_1 \\lambda_1^{k+1} \\mathbf{v}_1 +\\sum_{i=2}^n \\alpha_i \\lambda_i^{k+1} \\mathbf{v}_i =\\lambda_1^{k+1} \\left(\\alpha_1 \\mathbf{v}_1 +\\sum_{i=2}^n \\alpha_i \\mathbf{v}_i {\\left(\\frac{\\lambda_i }{\\lambda_1 }\\right)}^{k+1} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "and since $\\lambda_i / \\lambda_ 1 < 1$ then\n",
    "\n",
    "\\begin{align*}\n",
    "    \\lim_{k\\to \\infty } \\mathbf{e}^{(k+1)} =\\alpha_1 \\lambda_1^{k+1} \\mathbf{v}_1 .\n",
    "\\end{align*}\n",
    "\n",
    "This means that as the number of iterations increases, the error varies by a factor of $\\lambda_1^{k+1}$ where $\\lambda_1$ is the largest eigenvalue of $T$ which is known as the **spectral radius**.\n",
    "\n",
    "````{admonition} Definition: Spectral radius\n",
    ":class: note\n",
    ":name: spectral-radius-definition\n",
    "\n",
    "Let $\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$ be the eigenvalues of a matrix $A$ then the spectral radius of $A$ denoted by $\\rho(A)$ is\n",
    "\n",
    "```{math}\n",
    ":label: spectral-radius-definition\n",
    "\n",
    "\\begin{align*}\n",
    "    \\rho(A) = \\max_i(|\\lambda_i|).\n",
    "\\end{align*}\n",
    "```\n",
    "````\n",
    "\n",
    "```{admonition} Theorem: Convergence criteria for an indirect method\n",
    ":class: important\n",
    ":name: indirect-methods-convergence-criteria-theorem\n",
    "\n",
    "The spectral radius of $T$ gives us the following information about an indirect method\n",
    "\n",
    "- If $\\rho (T) > 1$ then the errors will increase over each iteration, therefore for an indirect method to converge to the solution we require $\\rho (T)< 1$.\n",
    "- The smaller the value of $\\rho (T)$ the faster the errors will tend to zero.\n",
    "\\end{itemize}\n",
    "```\n",
    "\n",
    "````{admonition} Example 7.3\n",
    ":class: seealso\n",
    ":name: convergence-example\n",
    "\n",
    "Show that the Jacobi and Gauss-Seidel methods are convergent of the system of linear equations from [example 7.1](jacobi-method-example).\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The coefficient matrix for this linear system is\n",
    "\n",
    "\\begin{align*}\n",
    "    A = \\begin{pmatrix} 4 & 3 & 0 \\\\ 3 & 4 & -1 \\\\ 0 & -1 & 4 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "so\n",
    "\n",
    "\\begin{align*}\n",
    "    L &= \\begin{pmatrix} 0 & 0 & 0 \\\\ 3 & 0 & 0 \\\\ 0 & -1 & 0 \\end{pmatrix}, &\n",
    "    D &= \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & 4 \\end{pmatrix}, \\\\\n",
    "    U &= \\begin{pmatrix} 0 & 3 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 0 & 0 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "The iteration matrices for the Jacobi and Gauss-Seidel methods are given in equations {eq}`jacobi-method-iteration-matrix-equation` and {eq}`gauss-seidel-method-iteration-matrix-equation` which for this system are\n",
    "\n",
    "\\begin{align*}\n",
    "    T_J &= -D ( L + U) \n",
    "    = -\\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & 4 \\end{pmatrix} \\left(\n",
    "    \\begin{pmatrix} 0 & 0 & 0 \\\\ 3 & 0 & 0 \\\\ 0 & -1 & 0 \\end{pmatrix} +\n",
    "    \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & 4 \\end{pmatrix} \\right) \\\\\n",
    "    &= - \\begin{pmatrix} \\frac{1}{4} & 0 & 0 \\\\ 0 & \\frac{1}{4} & 0 \\\\ 0 & 0 & \\frac{1}{4} \\end{pmatrix}\n",
    "    \\begin{pmatrix} 0 & 3 & 0 \\\\ 3 & 0 & -1 \\\\ 0 & -1 & 0 \\end{pmatrix} \n",
    "    = \\begin{pmatrix} 0 & -\\frac{3}{4} & 0 \\\\ -\\frac{3}{4} & 0 & \\frac{1}{4} \\\\ 0 & \\frac{1}{4} & 0 \\end{pmatrix}, \\\\\n",
    "    T_{GS} &= - (L + D)^{-1} U \n",
    "    = - \\begin{pmatrix} 3 & 0 & 0 \\\\ 3 & 4 & 0 \\\\ 0 & -1 & 4 \\end{pmatrix}^{-1}\n",
    "    \\begin{pmatrix} 0 & 3 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 0 & 0 \\end{pmatrix} \\\\ \n",
    "    &= \\begin{pmatrix} -\\frac{1}{4} & 0 & 0 \\\\ \\frac{3}{16} & \\frac{1}{4} & 0 \\\\ \\frac{3}{64} & -\\frac{1}{16} & \\frac{1}{4} \\end{pmatrix}\n",
    "    \\begin{pmatrix} 0 & 3 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 0 & 0 \\end{pmatrix} =\n",
    "    \\begin{pmatrix} 0 & -\\frac{3}{4} & 0 \\\\ 0 & \\frac{9}{16} & \\frac{1}{4} \\\\ 0 & \\frac{9}{64} & \\frac{1}{16} \\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Calculating the spectral radius for these iteration matrices gives $\\rho(T_J )=0.7906$ and $\\rho (T_{GS})=0.625$ which are both less than 1 so both of these methods are convergent for this system. Furthermore, the Gauss-Seidel method will converge faster than the Jacobi method since it has a smaller spectral radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fa87b7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.75 -0.  ]\n",
      " [-0.75 -0.    0.25]\n",
      " [-0.    0.25 -0.  ]]\n",
      "[[-0.       -0.75     -0.      ]\n",
      " [-0.        0.5625    0.25    ]\n",
      " [-0.        0.140625  0.0625  ]]\n",
      "[-7.90569415e-01  7.90569415e-01  6.40060725e-19]\n",
      "[-0.     0.625  0.   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def jacobi_iteration_matrix(A):\n",
    "    L = np.tril(A, -1)\n",
    "    U = np.triu(A, 1)\n",
    "    D = A - L - U\n",
    "    return - np.dot(np.linalg.inv(D), L + U)\n",
    "\n",
    "\n",
    "def gauss_seidel_iteration_matrix(A):\n",
    "    L = np.tril(A, -1)\n",
    "    U = np.triu(A, 1)\n",
    "    D = A - L - U\n",
    "    return - np.dot(np.linalg.inv(L + D), U)\n",
    "\n",
    "A = np.array([[4, 3, 0], [3, 4, -1], [0, -1, 4]])\n",
    "\n",
    "T_J = jacobi_iteration_matrix(A)\n",
    "T_GS = gauss_seidel_iteration_matrix(A)\n",
    "print(T_J)\n",
    "print(T_GS)\n",
    "print(np.linalg.eigvals(T_J))\n",
    "print(np.linalg.eigvals(T_GS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac05bed",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎡ 0    -1   1/4⎤\n",
      "⎢              ⎥\n",
      "⎢-3/4   0   -1 ⎥\n",
      "⎢              ⎥\n",
      "⎣ 0    1/4   0 ⎦\n",
      "⎡0  -3/4   0  ⎤\n",
      "⎢             ⎥\n",
      "⎢0  9/16  1/4 ⎥\n",
      "⎢             ⎥\n",
      "⎣0  9/64  1/16⎦\n",
      "⎧         3   √5     √5   3   ⎫\n",
      "⎨-3/4: 1, ─ - ──: 1, ── + ─: 1⎬\n",
      "⎩         8   8      8    8   ⎭\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "def jacobi_iteration_matrix(L, D, U):\n",
    "    return - D.inv() * (L + U)\n",
    "\n",
    "\n",
    "def gauss_seidel_iteration_matrix(L, D, U):\n",
    "    L = np.tril(A, -1)\n",
    "    U = np.triu(A, 1)\n",
    "    D = A - L - U\n",
    "    return - (L + D).inv() * U\n",
    "\n",
    "A = Matrix([[4, 3, 0], [3, 4, -1], [0, -1, 4]])\n",
    "L = Matrix([[0, 0, 0], [3, 0, 0], [0, -1, 0]])\n",
    "D = Matrix([[4, 0, 0], [0, 4, 0], [0, 0, 4]])\n",
    "U = Matrix([[0, 4, -1], [0, 0, 4], [0, 0, 0]])\n",
    "\n",
    "T_J = jacobi_iteration_matrix(L, D, U)\n",
    "T_GS = gauss_seidel_iteration_matrix(L, D, U)\n",
    "pprint(T_J)\n",
    "pprint(T_GS)\n",
    "\n",
    "pprint(T_J.eigenvals())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
